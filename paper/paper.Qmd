---
title: "Something something values disclosure replication"
author: "Daniel J. Hicks and Emilio Lobato"
abstract: |
  abstract
toc: true
execute:
    echo: false
bibliography: |
  transparency-Hicks.yaml
format: 
    html: default
    pdf: default
---

```{r}
#| message: false
#| results: hide

library(gtsummary)
library(kableExtra)
library(here)
here()
out_dir = here('out')

print_tbl = function(x) {
    x |> 
        as_kable_extra(booktabs = TRUE) |> 
        kable_styling(latex_options = c('scale_down'))
}
```

# Introduction #

Over the past 15 years, many philosophers of science have rejected the ideal of value-free science and related, traditional understandings of objectivity and political neutrality of science [@DouglasSciencePolicyValuefree2009; @ElliottTapestryValuesIntroduction2017].  According to the value-free ideal, social and political values — such as feminism, environmentalism, or the protection of human health — have no legitimate role to play in the evaluation of scientific hypotheses.  The value-free ideal is compatible with allowing social and political values to play important roles earlier and later in inquiry.  Specifically, these values may legitimately shape the content and framing of research questions — researchers might decide to investigate whether chemical X causes cancer out of a concern to protect human health — and will be essential when scientific findings are used to inform public policy — say, banning the use of chemical X.  But, according to the value-free ideal, these values must not influence the collection and analysis of data and the process of reaching an overall conclusion about whether or not chemical X causes cancer.  

Challenges to the value-free ideal argue that at least some social and political values may, or even should, play a role in the evaluation of scientific hypotheses.  Keeping with the example, the question of whether chemical X causes cancer has much more significant social and political implications than the question of whether chemical X fluoresces under ultraviolet light.  So, in the interest of protecting human health, it would be appropriate to *scientifically* accept the hypothesis that chemical X is carcinogenic based on relatively provisional evidence [@CranorSocialBenefitsExpedited1995; @ElliottNonepistemicValuesMultiple2014; @FernandezPintoLegitimizingValuesRegulatory2019].  

While this kind of argument indicates that at least some social and political values may or should play at least some role in the evaluation of at least some scientific hypotheses, it doesn't provide us with much positive guidance:  which values, playing which roles, in the evaluation of which hypotheses?  [@HicksNewDirectionScience2014]  One (partial) answer to this set of questions appeals to the ideal of transparency:  scientists should disclose to the public the social and political values that have influenced their research [@ElliottSciencePolicyTransparency2014; @McKaughanBacktrackingEthicsFraming2013].  But some philosophers have objected to this transparency proposal, arguing that it might actually undermine trust in science.  According to this objection, members of the public generally accept the ideal of value-free science; values disclosures would violate this ideal, making scientists (incorrectly) appear biased and untrustworthy [@JohnEpistemicTrustEthics2017; @KovakaClimateChangeDenial2021].  

This objection is an empirical prediction: if scientists disclose their values, they will be perceived as less trustworthy.  @ElliottValuesEnvironmentalResearch2017 conducted an online survey study to evaluate this prediction.  However, these authors collected data from a somewhat small sample using Amazon Mechanical Turk, and adopted an analytical approach that significantly diluted their sample across different conditions.  

In this paper, we report the results of a replication of @ElliottValuesEnvironmentalResearch2017 study 1, using a larger, more reliable sample and a more statistically efficient analytical approach.  



# Methods and Materials #

## Experimental design ##

We use the same experimental stimulus and design as @ElliottValuesEnvironmentalResearch2017, embedded within a larger survey with other results not reported here.  In the replication component, participants are randomly assigned to one of $3 \times 2$ (values \times harm) conditions.  In each condition, participants are first shown a single presentation slide and the following explanatory text: 

> For several decades, a scientist named Dr. Riley Spence has been doing research on chemicals used in consumer products. One chemical—Bisphenol A, popularly known as BPA—is found in a large number of consumer products and is suspected of posing risks to human health. Yet, scientists do not agree about these possible health risks. Dr. Spence recently gave a public talk in Washington, D.C., about BPA research. Here is the final slide from Dr. Spence's presentation. 

| No other information about the (fictional) Dr. Spence is provided.  The content of the slide varies across the conditions.  Each slide has the header "My conclusion," followed by a list of 2 or 3 bullets.  The first bullet, if present, makes a values disclosure, stating that either economic growth or public health should be a top national priority.  This first bullet is not present in the "no disclosure" values condition.  The second bullet, identical across conditions, states "I examined the scientific evidence on potential health risks of BPA."  The third bullet concludes that BPA either does or does not cause harm to people, depending on whether the subject is in the "causes harm" or "does not cause harm" condition. 

After viewing the slide, the participant is then asked to rate Dr. Spence's trustworthiness using a semantic differential scale.  @ElliottValuesEnvironmentalResearch2017 did not cite a source for their scale; we used the Muenster Epistemic Trustworthiness Inventory [METI\; @HendriksMeasuringLaypeopleTrust2015], which substantially overlaps but is not identical to the @ElliottValuesEnvironmentalResearch2017 scale.  On the METI, participants rate the target scientist (the fictional Dr. Spence) on a 1-7 scale for 14 items, where each item is anchored at the ends by a pair of words, such as competent-incompetent or responsible-irresponsible.  In both @ElliottValuesEnvironmentalResearch2017 and our replication analysis, all items were averaged together to form a 1-7 composite measure of trustworthiness.  To aid interpretation, in the analysis the direction of the scale has been set so that increased values correspond to increased perceived trustworthiness.  

Ethicists make a key distinction between trust and trustworthiness [@BaierTrustAntitrust1986].  Trust is a verb: placing one's trust in someone else, with respect to some activity or domain.  Trustworthiness is an assessment, of whether or not that trust is appropriate.  In the experiment, participants might trust Dr. Spence's conclusion even if they judge Spence to be untrustworthy, or vice versa; though we would typically expect these two to go together.  As its name indicates, METI assesses perceived trustworthiness, not trust (such as accepting Dr. Spencer's conclusion about BPA).  

@ElliottValuesEnvironmentalResearch2017 explain that they selected BPA as a complex, ongoing, public scientific controversy.  For our replication, we chose to keep BPA, rather than switching to a different public scientific controversy with a higher profile in 2021, such as climate change, police violence, voter fraud, or any of numerous aspects of the Covid-19 pandemic.  All of these controversies are highly politically charged, with prominent public experts and counterexperts [@GoldenbergVaccineHesitancyPublic2021 100-1, ch. 6].  While we anticipated some effects of political partisanship in the BPA case, we felt it would be less likely to swamp the values disclosure that was our primary interest.  

After filling in the METI, participants provided demographic information and other sections of the survey that are not examined here.  Due to researcher error, a question about the participants' values (whether they prioritize economic growth or public health) was omitted in the first wave of data collection; this question was asked in a followup wave.  

## Replication hypotheses and analytical approach ##

We identified 5 major findings from @ElliottValuesEnvironmentalResearch2017 for our replication attempt:  

H1. Modest correlation between values and ideology
~ \(a\) Political liberals are more likely to prioritize public health over economic growth, compared to political conservatives; but (b) a majority of political conservatives prioritize public health.  

H2. Consumer risk sensitivity
~ Scientists who find that a chemical harms human health are perceived as more trustworthy than scientists who find that a chemical does not cause harm. 

H3. Transparency penalty
~ Scientists who disclose values are perceived as less trustworthy than scientists who do not.  

H4. Shared values
~ Given that the scientist discloses values, if the participant and the scientist share the same values, the scientist is perceived as more trustworthy than if the participant and scientist have discordant values.  

H5. Variation in effects
~ The magnitude of the effects 2-4 vary depending on whether the participant prioritizes public health or economic growth.  

Hypothesis H3, the transparency penalty, corresponds to the objection to transparency:  disclosing values undermines trust in science.  However, the shared values effect works in the opposite direction, counteracting the transparency penalty.  

Hypothesis 1 was analyzed using Spearman rank order correlation and visually.  Hypotheses 2-5 were analyzed using linear regression models as a common framework, with a direct acyclic graph (DAG) constructed a priori to identify appropriate adjustments (covariates) for H4 and 5.  Because @ElliottValuesEnvironmentalResearch2017 made their data publicly available, and our analytical approaches differ somewhat from theirs, we conducted parallel analyses of their data, and report these parallel results for H2 and 3.  Exploratory data analysis was used throughout to support data validation and aid interpretation.  


## Participants ##

Participants were recruited using the online survey platform Prolific, and the survey was administered in a web browser using Qualtrics.  Prolific has an option to draw samples that are balanced to be representative by age, binary gender, and a 5-category race variable (taking values Asian, Black, Mixed, Other, and White) for US adults *[https://researcher-help.prolific.co/hc/en-gb/articles/360019238413-Representative-samples-FAQ]*.  A recent analysis finds that Prolific produces substantially higher quality data than Amazon Mechanical Turk for online survey studies, though three of the five authors are affiliated with Prolific [@PeerDataQualityPlatforms2021].  Preliminary power analysis recommended a sample of approximately 1,000 participants to reliably detect non-interaction effects (H1-4).  

The study was approved by the UC Merced IRB on August 17, 2021, and data collection ran October 18-20, 2021.  As mentioned above, due to researcher error a question about participants' values was not included in the original survey.  A followup survey asking this question of the same group of participants was conducted December 8, 2021 through March 5, 2022.  


## Software and reproducibility ##

Data cleaning and analysis was conducted in R *[version, cite]*, with extensive use of the `tidyverse` suite of packages *[cite]*.  Regression tables were generated using the `gt` and `gtsummary` packages *[cites]*.  

*[Anonymized original data and reproducible code are available at <https://github.com/dhicks/transparency>.  Instructions in that repository explain how to automatically reproduce our analysis.]*






# Results #

After excluding participants who declined consent after opening the survey or did not complete the survey, we had 988 participants in the full analysis sample.  660 participants (67%) were randomly assigned to a values disclosure condition (scientist prioritizes either economic growth or public health); 844 participants (85%) responded to the followup question about their own values (participant prioritizes economic growth or public health).  Consequently, subsamples for hypotheses 4 and 5 were substantially smaller than the full analysis sample.  

*[participant demographics]*  

Critically, our data are unlikely to be representative by education level and political ideology.  In 2021, about 9% of US adults 25 or over had a less than high school education, and 38% had a Bachelor's degree or higher.  Only 1% of our participants reported a less than high school education, and 57% reported a Bachelor's degree or higher.  *[<https://www.census.gov/library/visualizations/time-series/demo/cps-historical-time-series.html> fig. 2]*  For political ideology, the General Social Survey has consistently found over several decades that about 30% of US adults identify as liberal, about 30% identify as conservative, and about 40% as moderate *[https://gssdataexplorer.norc.org/variables/178/vshow]*.  Among our participants, liberals outnumber conservatives *[by over 2:1]* (@fig-part-values).  Both overrepresentation of college graduates and underrepresentation of conservatives (especially conservatives with strong anti-institutional views) are known issues in public opinion polling [@KennedyEvaluation2016Election2018].  In exploratory data analysis, we noted that there was essentially no correlation between political ideology and perceived trustworthiness *[supplement]*.  This was surprising, since general trust/distrust in science has become a partisan phenomenon over the last few decades:  data from the General Social Survey shows increasing trust in science from liberals and decreasing trust from conservatives [@GauchatPoliticizationSciencePublic2012; @LeePartyPolarizationTrust2021], and many (though not all) prominent public controversies align with liberal-conservative partisanship *[cite]*.  

Because of these representation issues, insofar as some political conservatives are both less likely to participate in studies on Prolific (or at least in our particular study) and likely to perceive Spence as less trustworthy, this will produce omitted variable bias for analyses that require adjustment by political ideology.  Analysis of our a priori DAG indicated that, for the hypotheses examined here, this adjustment was not necessary in any case.  When some adjustment was necessary (H4-5), we included political ideology along with other demographic variables in an alternative model specification as a robustness check.  In line with the DAG, in no case did these robustness checks produce indications of omitted variable bias.  



## H1: Correlation between values and ideology

We tested the hypothesis of a modest correlation between values and ideology in two ways. First, to test (H1a) whether political liberals are more likely to prioritize public health over economic growth compared to conservatives, we conducted a Spearman's rank order correlation. Results revealed a significant correlation in line with the hypothesis, Spearman's rho = -.47, p < .001. Political liberals were more likely than conservatives to value public health over economic growth. To test (H1b) that a majority of political conservatives priortize public health over economic growth we cross-tabulated the data. Results revealed that, contrary to the hypothesis, slightly more than half of the self-reported political conservatives in our sample reported valuing economic growth (51.7%) over public health (48.3%). See @fig-part-values. 

![Participant values by political ideology. (A) Absolute counts, (B) shares within political ideology categories.  Panel (A) shows that our sample substantially over-represents political liberals.](`r here(out_dir, '03_part_values.png')`){#fig-part-values} 

## H2 and H3: Consumer risk sensitivity and transparency penalty

Next, we tested the hypotheses that (H2) scientists who find a chemical harms human health are perceived as more trustworthy than scientist who find that a chemical does not cause harm and (H3) a scientist who discloses values are perceived as less trustworthy than a scientist who does not. For this analysis, we regressed participants' METI ratings onto both the Conclusions and Disclosure experimental conditions. The full model was significant, adj. $R^2$= .148, F(2, 985) = 86.59, p < .001 (see @tbl-bc). Specifically, results revealed that the conclusions reported by the scientist predicted participants' perceived trustworthiness in line with our hypothesis. Participants rated the scientist who reported that BPA does not cause harm as less trustworthy ($M_{sd} = 4.48_{1.26}$) than the scientist who reported that BPA causes harm ($M_{sd} = 5.47_{1.12}$), $\beta$ = -0.99, t(985) = -13.09, p < .001. By contrast, the results do not provide evidence in favor of our hypothesis that a scientist disclosing their values ($M_{sd} = 4.94_{1.33}$) are perceived as less trustworthy than a scientist who does not disclose values  ($M_{sd} = 5.05_{1.21}$), $\beta$ = -0.12, t(985) = -1.46, p = .143. 

```{r}
#| label: tbl-bc
#| tbl-cap: "Regression analysis for hypotheses H2 (consumer risk sensitivity) and H3 (disclosure effect)"
readRDS(here(out_dir, '03_bc_tbl.Rds')) |> 
    print_tbl()
```

## H4: Shared values

Next, we tested the hypothesis that (H4) if the participant and scientist share the same values, the scientist is perceived as more trustworthy than if the participant and scientist do not share the same values. For this and related analyses, we only included data from participants who were assigned to either of the Disclosure conditions and self-reported their own values, reducing the sample to 567. Following this, we created a new Shared Values variable as a composite of the participants' reported values and the scientist's values. For this analysis, an a priori directed acyclic graphic (DAG) indicated that a univariate regression of participants' METI rating onto Shared Values would produce a biased estimate, that adjustments were required for both the participant's and scientist's values, and that including demographic variables would not effect this estimate [@fig-shared-dag].  While the univariate model was significant, adj. $R^2$= .029, F(1, 565) = 18.0, p < .001 [@tbl-shared model 1], after adjusting for scientist values Shared Values did not emerge as a significant predictor of participants' perceptions of the trustworthiness of the scientist [@tbl-shared models 2-4], indicating that the univariate estimate was indeed biased.  Rather, only the scientist's disclosed values significantly predicted how trustworthy participants rated the scientist, such that a scientist who disclosed valuing public health was rated as more trustworthy than a scientist who disclosed valuing economic growth.  This scientist values effect was robust across alternative model specifications, with an estimated effect of 0.6 (95% CI 0.4-0.8) [@tbl-shared models 2-5], again consistent with the DAG.  

![Directed acyclic graph (DAG) for analysis of the shared values effect.  If the DAG is faithful, adjusting for scientist values (`sci_values`) and participant values (`part_values`) is sufficient for estimating the effect of shared values on perceived trustworthiness (`METI`).  In particular, adjusting for demographics should not change the regression coefficient on shared values.](`r here(out_dir, '03_shared_values_dag.png')`){#fig-shared-dag}

```{r}
#| label: tbl-shared
#| tbl-cap: "Sequential regression analysis of hypothesis H4 shared values/scientist values effects"
readRDS(here(out_dir, '03_shared_values_tbl.Rds')) |> 
    print_tbl()
```

## H5: Variation in effects

We ran the following analyses to test our hypothesis that (H5) the magnitude of the effects found for the tests of H2-H4 vary depending on whether the participant prioritizes public health or economic growth. Results are presented in [@tbl-eb; @tbl-ec; @tbl-sci-part].

### Consumer risk sensitivity

To test whether the findings regarding consumer risk sensitivity vary as a function of participants' values, we regressed participants' METI ratings of the scientist in the stimuli onto the Conclusions condition, Participants' Values variable, and the Conclusions by Participants' values interaction term. The full model was significant, adj. $R^2$ = .173, F(3, 840) = 59.95, p < .001 ([@tbl-eb model 2]). As with the earlier analysis, results showed a main effect of the Conclusions condition, such that participants rated the scientist who reported that BPA does not cause harm as less trustworthy than the scientist who reported that BPA causes harm, $\beta$ = -0.75, t(840) = -4.51, p < .001. However, this effect was qualified by a significant interaction with participants' values, $\beta$ = -0.41, t(840) = -2.16, p = .031. Participants who prioritized public health and read about a scientist who concluded that BPA causes harm rated the scientist as more trustworthy ($M_{sd} = 5.56_{1.09}$) than participants with the same values who read about a scientist who concluded that BPA does not cause harm ($M_{sd} = 4.40_{1.24}$) ([@fig-conclusion-part]). 

```{r}
#| label: tbl-eb
#| tbl-cap: "Regression analysis of H5-consumer, interaction between participant values and consumer risk sensitivity"
readRDS(here(out_dir, '03_eb_tbl.Rds')) |> 
    print_tbl()
```

![Data, group means, and 95% confidence intervals for H5-consumer, interaction of consumer risk sensitivity and participant values. Panels correspond to participant values.](`r here(out_dir, '03_conclusion_part.png')`){#fig-conclusion-part}


### Transparency penalty

To test whether the findings above about a hypothesized transparency penalty may vary based on participants' values, we regressed participants' METI ratings of the scientist onto the Disclosure condition variable, Participants' Values variable, and the Disclosure by Participants' Values interaction term. The full model was not significant, adj. $R^2$< .001, F(3, 840) = 1.19, p = .31 [@tbl-ec model 2]. As with the earlier analysis, our results do not provide evidence for a transparency penalty to the perceived trustworthiness of a scientist, either in general or interacting with participants' own reported values, $\beta$ = -0.23, t(840) = -1.07, p = 0.286. 

```{r}
#| label: tbl-ec
#| tbl-cap: "Regression analysis of H5-transparency, interaction between participant values and transparency penalty"
readRDS(here(out_dir, '03_ec_tbl.Rds')) |> 
    print_tbl()
```



### Shared values and scientist values

Without adjustments, Shared Values appears to have a substantial interaction with Participant Values:  Shared Values appears to increase perceived trustworthiness for participants who value public health, while decreasing perceived trustworthiness for participants who value economic growth [@fig-shared-part].  However, as indicated by our analysis for a potential shared values effect, the estimated effects for both shared values and participant values are biased if the model is not adjusted for scientist values.  (@fig-shared-dag and @tbl-shared show how this bias occurs.  Shared Values is a collider between Participant Values and Scientist Values; hence, if a model specification includes Participant Values and Shared values but not Scientist Values, there is an open path between Participant Values and METI, resulting in a biased estimate for Participant Values.)  Because Shared Values is the logical biconditional of Participant Values and Scientist Values, and the Shared Values $\times$ Participant Values interaction term is their logical conjunction, including all four variables (Participant, Scientist, and Shared Values, along with the interaction term) in a regression model creates perfect collinearity.  

![Data, group means, and 95% confidence intervals for H5d, interaction of shared values and participant values.  Panels correspond to participant values.](`r here(out_dir, '03_shared_part.png')`){#fig-shared-part}

As we found above, rather than a shared values effect there appears to be an effect of scientist values.  Replotting the same data as @fig-shared-part based on scientist values, rather than shared values, suggests a more consistent effect across participant values (@fig-sci-part). Therefore, we conducted an unplanned post hoc analysis to test whether an effect of scientist values might vary as a function of participants values.  We regressed participants' METI of the scientist in the stimulus onto the Scientist Values variable, Participants' Values variable, and their interaction (@tbl-sci-part). This model was significant, adj. $R^2$ = 0.065, F(3, 563) = 14.15, p < .001. The estimate for the scientist values term was significant, $\beta$ = 0.53, t(563) = 2.26, p = 0.02, while the estimate for the interaction term was not, $\beta$ = 0.20, t(563) = 0.75, p = 0.45.  Estimates for both variables had large uncertainties, with confidence intervals of about 1 (95% confidence intervals, scientist values: 0.07, 1.0; interaction term: -0.32, 0.72).  

![Data, group means, and 95% confidence intervals for a potential interaction of scientist values and participant values. Panels correspond to participant values. This figure is identical to @fig-shared-part, except the columns in the economic growth panel have been switched.](`r here(out_dir, '03_sci_part.png')`){#fig-sci-part}

```{r}
#| label: tbl-sci-part
#| tbl-cap: "Regression analysis of interaction between scientist values and participant values"
readRDS(here(out_dir, '03_sci_part_tbl.Rds')) |> 
    print_tbl()
```

*[maybe move to conclusion]*
The evidence here suggests that if a scientist discloses their values alongside their presentation of scientific research, what values they share predicts their perceived trustworthiness, and that a scientist who discloses valuing public health will tend to be perceived as more trustworthy than the scientist who discloses valuing economic growth. 


# Conclusion #

@tbl-summary summarizes the results of our replication attempts. We were able to successfully replicate the correlation between political ideology and valuing public health and consumer risk sensitivity (a scientist who concludes BPA is harmful is perceived as more trustworthy), and in addition found evidence of an interaction between consumer risk sensitivity and whether the participant values public health (participants who value public health have more extreme reactions to the scientist's conclusion).  

We did not find evidence for a transparency penalty or shared values effect.  And we found evidence of a scientist values effect, which also did not appear in @ElliottValuesEnvironmentalResearch2017.  

+-------------------+------------------------------------------+-------------+
|                   | Hypothesis                               | Replicated? |
+===================+==========================================+=============+
|               H1a | Liberals prioritize public health        | yes         |
|                   | rel. to conservatives                    |             |
+-------------------+------------------------------------------+-------------+
|               H1b | Majority of conservatives prioritize     | no          |
|                   | public health                            |             |
+-------------------+------------------------------------------+-------------+
|                H2 | Sci. who find chemical is harmful        | yes         |
|                   | perceived as more trustworthy            |             |
+-------------------+------------------------------------------+-------------+
|                H3 | Sci. who disclose values perceived as    | no          |
|                   | less trustworthy                         |             |
+-------------------+------------------------------------------+-------------+
|                H4 | Given sci. discloses values,             | no          |
|                   | sci. who shared values with participant  |             |
|                   | perceived as more trustworthy            |             |
+-------------------+------------------------------------------+-------------+
|         Unplanned | Given sci. discloses values,             |yes$^\dagger$|
|                   | sci. who values public health            |             |
|                   | perceived as more trustworthy            |             |
+-------------------+------------------------------------------+-------------+
|       H5-consumer | Interaction btwn. sci. conclusion (H2)   | yes         |
|                   | and participant values                   |             |
+-------------------+------------------------------------------+-------------+
|   H5-transparency | Interaction btwn. values disclosure (H3) | no          |
|                   | and participant values                   |             |
+-------------------+------------------------------------------+-------------+
|         H5-shared | Interaction btwn. shared values (H4)     | $^\star$    |
|                   | and participant values                   |             |
+-------------------+------------------------------------------+-------------+
|    H5-sci. values | Interaction btwn. scientist values       | no$^\dagger$|
|                   | and participant values                   |             |
+-------------------+------------------------------------------+-------------+

: Summary of replication results.  $^\star$: The shared values $\times$ participant values interaction specification had perfect multicollinearity and could not be fit.  $^\dagger$: For these unplanned analyses, "yes" indicates that we found evidence supporting the stated hypothesis, and "no" indicates that we did not find such evidence. {#tbl-summary}


@ElliottValuesEnvironmentalResearch2017 claim evidence for a shared values effect by comparing values disclosure vs. no disclosure (that is, estimating a transparency effect) in quasi-independent subsamples across 8 cells (participant values $\times$ scientist conclusion $\times$ scientist values; @ElliottValuesEnvironmentalResearch2017 fig. 1).  This approach is difficult to interpret; their reasoning seems to be that this estimate is statistically significant in 4/8 cells, and in 3/4 of these cells (1 where respondent values economic growth) the participant and scientist share values.  But these analyses are underpowered (for example, sample sizes are well below 100 for some of the cells in which participants value economic growth) and the overall approach cannot distinguish a shared values effect from other potential effects (scientist values, participant values).  Applying our regression analysis approach to the data published by @ElliottValuesEnvironmentalResearch2017, the estimate for shared values was not statistically significant, $\beta$=0.29, t(335)=1.75, p=0.08; while the estimate for scientist values was statistically significant, $\beta$=0.41, t(335)=2.48, p=0.014.  It seems likely that claims of a shared values effect were the result of misinterpreting a confusing statistical approach.  *[trying to put this as nice as possible]*

The disagreement over a transparency penalty is more difficult to explain.  Using our approach and the data from @ElliottValuesEnvironmentalResearch2017, the estimate for a values disclosure was statistically significant (@tbl-bc model 1).  One possible explanation is that, over the course of the Covid-19 pandemic, members of the general public have become used to "scientists" (including both bench researchers and public health officials) making claims about the importance of protecting public health.  (And, more recently, Leana Wen and some other prominent physicians and public health officials have argued for the importance of a "return to normal," which might be understood as prioritizing economic growth.)  A values disclosure that was regarded as violating the value-free ideal, pre-pandemic, might now be seen as routine.  

*[further work]*



# References #
